# Project : Landmark Detection and Tracking (SLAM)


In this project, I implement SLAM (Simultaneous Localization and Mapping) for a 2-dimensional world. Sensor and motion data gathered by a simulated robot is used to create a map of an environment. SLAM gives us a way to track the location of a robot in the world in real-time and identify the locations of landmarks such as buildings, trees, rocks, etc.

The project will be broken up into three Python notebooks :

**Notebook 1 : Robot Moving and Sensing**

**Notebook 2 : Omega and Xi, Constraints**

**Notebook 3 : Landmark Detection and Tracking**

Below is an example of a 2D robot world with landmarks (purple x's) and the robot (a red 'o') located and found using only sensor and motion data collected by that robot. This is just one example for a 50x50 grid world :



**Tools : NumPy, Pandas, Seaborn**

The Udacity repository for this project: [Project: Landmark Detection and Tracking ](https://github.com/udacity/P3_Implement_SLAM)
Short description :
Use feature detection and keypoint descriptors to build a map of the environment with SLAM (simultaneous
localization and mapping).
Implement a robust method for tracking an object over time, using elements of probability, motion models,
and linear algebra. This project tests your knowledge of localization techniques that are widely used in
autonomous vehicle navigation.
